{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebe75e7e",
   "metadata": {},
   "source": [
    "# Step 1: Converting from Run-Level Data to floor-level data\n",
    "\n",
    "This first stage takes the nested run-level metrics dump (the 123k run november JSON logs from the [STS Metrics Dump Thread](https://www.reddit.com/r/slaythespire/comments/jt5y1w/77_million_runs_an_sts_metrics_dump/)) and turns it into a clean, **floor-by-floor table**. This allows for broader, more useful modeling. Instead of learning how likely a run's end state was to winning, we'd like to track a run's victory likelihood over its course!\n",
    "\n",
    "Each original run JSON is flattened into one row per floor, with shared run metadata (seed, character, ascension, victory, win rate) plus per-floor state: HP and gold, map node type, card and relic rewards, events, campfire actions, shop purchases, damage taken, and more.\n",
    "\n",
    "Crucially, this pass also reconstructs the evolving deck and relic loadout: starting from the character’s base deck, it applies card picks, event rewards, purges, and upgrades to produce an exact deck list on every floor, and tracks relic acquisitions (including event and boss relics) to maintain a running relic list as well. The result is a single, tabular, csv dataset where each row represents “one floor of one run,” with fully specified deck and relic state, ready for downstream feature engineering and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d3ab927f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"A module for handling the conversion from nested JSON data to a clean tabular dataset\"\"\"\n",
    "\n",
    "# Rich Progress Bar for Nice Loading Display\n",
    "from copy import deepcopy\n",
    "\n",
    "from rich.console import Console\n",
    "\n",
    "console = Console()\n",
    "\n",
    "\n",
    "def process_run(run: dict, run_id = None) -> list[dict]:\n",
    "    \"\"\"Flatten a Slay the Spire run into floor-level state records, including running deck state.\n",
    "    \n",
    "    If no run_id is provided will use the play_id unique identifier from the record\"\"\"\n",
    "    local_run = run[\"event\"]\n",
    "    \n",
    "    if run_id is None:\n",
    "        run_id = local_run['play_id']\n",
    "\n",
    "    floors = init_floors(local_run, run_id)\n",
    "    add_base_stats(local_run, floors)\n",
    "    add_pathing(local_run, floors)\n",
    "    add_card_choices(local_run, floors)\n",
    "    add_relics(local_run, floors)\n",
    "    add_events(local_run, floors)\n",
    "    add_campfires(local_run, floors)\n",
    "    add_purchases(local_run, floors)\n",
    "    add_damage(local_run, floors)\n",
    "    add_deck_state(local_run, floors)\n",
    "    add_relic_state(local_run, floors)\n",
    "\n",
    "    return floors\n",
    "\n",
    "\n",
    "def safe_get_floor(d: dict):\n",
    "    \"\"\"Safely extract a floor index. Returns None if missing, else int.\"\"\"\n",
    "    f = d.get(\"floor\")\n",
    "    if f is None:\n",
    "        return None\n",
    "    return int(f)\n",
    "\n",
    "\n",
    "def init_floors(run: dict, run_id: int) -> list[dict]:\n",
    "    \"\"\"Basic Initialization of Row Structure and Shared Run Characteristics/Labels\"\"\"\n",
    "    n_floors = run.get(\"floor_reached\", 0)\n",
    "    victory = run.get(\"victory\", False)\n",
    "    character = run.get(\"character_chosen\", None)\n",
    "    asc_level = run.get(\"ascension_level\", None)\n",
    "    is_asc = run.get(\"is_ascension\", False)\n",
    "    win_rate = run.get(\"win_rate\", None)\n",
    "\n",
    "    return [\n",
    "        {\n",
    "            \"run_id\": run_id,\n",
    "            \"floor\": f,\n",
    "            \"victory\": victory,\n",
    "            \"character\": character,\n",
    "            \"asc_level\": asc_level,\n",
    "            \"is_ascension\": is_asc,\n",
    "            \"win_rate\": win_rate,\n",
    "        }\n",
    "        for f in range(n_floors + 1)\n",
    "    ]\n",
    "\n",
    "\n",
    "def add_base_stats(run: dict, floors: list[dict]):\n",
    "    \"\"\"Add floor level current stats to the running dictionary\"\"\"\n",
    "    for i, (max_hp, cur_hp, gold) in enumerate(\n",
    "        zip(\n",
    "            run.get(\"max_hp_per_floor\", []),\n",
    "            run.get(\"current_hp_per_floor\", []),\n",
    "            run.get(\"gold_per_floor\", []),\n",
    "        )\n",
    "    ):\n",
    "        if i < len(floors):\n",
    "            floors[i][\"max_hp\"] = max_hp\n",
    "            floors[i][\"cur_hp\"] = cur_hp\n",
    "            floors[i][\"gold\"] = gold\n",
    "\n",
    "\n",
    "def add_pathing(run: dict, floors: list[dict]):\n",
    "    \"\"\"Align path symbols with correct floor indices.\"\"\"\n",
    "    path = run.get(\"path_per_floor\", [])\n",
    "    n = len(floors)\n",
    "\n",
    "    for f in range(n):\n",
    "        if f == 0:\n",
    "            floors[f][\"path_symbol\"] = None\n",
    "            floors[f][\"next_path_symbol\"] = path[0] if len(path) > 0 else None\n",
    "        else:\n",
    "            idx = f - 1\n",
    "            floors[f][\"path_symbol\"] = path[idx] if idx < len(path) else None\n",
    "            floors[f][\"next_path_symbol\"] = (\n",
    "                path[idx + 1] if (idx + 1) < len(path) else None\n",
    "            )\n",
    "\n",
    "\n",
    "def add_card_choices(run: dict, floors: list[dict]):\n",
    "    \"\"\"Add Cards picked for Reinforcement Learning models\n",
    "    Ideally, these features could be used to represent a player picking X while they should have picked Y\n",
    "    \"\"\"\n",
    "    for choice in run.get(\"card_choices\", []):\n",
    "        f = safe_get_floor(choice)\n",
    "        if f is None or f >= len(floors):\n",
    "            return\n",
    "        floors[f][\"card_picked\"] = choice.get(\"picked\")\n",
    "        for j, np in enumerate(choice.get(\"not_picked\", [])):\n",
    "            floors[f][f\"not_picked_{j + 1}\"] = np\n",
    "\n",
    "def add_relics(run: dict, floors: list[dict]):\n",
    "    for relic in run.get(\"relics_obtained\", []):\n",
    "        f = safe_get_floor(relic)\n",
    "        if f is None or f >= len(floors):\n",
    "            return\n",
    "        floors[f][\"relic_obtained\"] = relic.get(\"key\")\n",
    "\n",
    "\n",
    "def add_events(run: dict, floors: list[dict]):\n",
    "    for ev in run.get(\"event_choices\", []):\n",
    "        f = safe_get_floor(ev)\n",
    "        if f is None or f >= len(floors):\n",
    "            return\n",
    "        floors[f][\"event_name\"] = ev.get(\"event_name\")\n",
    "        floors[f][\"event_choice\"] = ev.get(\"player_choice\")\n",
    "        floors[f][\"event_cards_obtained\"] = ev.get(\"cards_obtained\", [])\n",
    "        floors[f][\"event_relics_obtained\"] = ev.get(\"relics_obtained\", [])\n",
    "\n",
    "\n",
    "def add_campfires(run: dict, floors: list[dict]):\n",
    "    for camp in run.get(\"campfire_choices\", []):\n",
    "        f = safe_get_floor(camp)\n",
    "        if f is None or f >= len(floors):\n",
    "            return\n",
    "        floors[f][\"campfire_action\"] = camp.get(\"key\")\n",
    "        floors[f][\"campfire_target\"] = camp.get(\"data\")\n",
    "\n",
    "\n",
    "def add_purchases(run: dict, floors: list[dict]):\n",
    "    for item, f in zip(\n",
    "        run.get(\"items_purchased\", []), run.get(\"item_purchase_floors\", [])\n",
    "    ):\n",
    "        if f < len(floors):\n",
    "            floors[f].setdefault(\"items_purchased\", []).append(item)\n",
    "    for f in floors:\n",
    "        if \"items_purchased\" in f:\n",
    "            f[\"items_purchased\"] = \",\".join(f[\"items_purchased\"])\n",
    "\n",
    "\n",
    "def add_damage(run: dict, floors: list[dict]):\n",
    "    for d in run.get(\"damage_taken\", []):\n",
    "        f = safe_get_floor(d)\n",
    "        if f is None or f >= len(floors):\n",
    "            return\n",
    "        floors[f][\"combat_enemies\"] = d.get(\"enemies\")\n",
    "        floors[f][\"combat_damage\"] = d.get(\"damage\", 0)\n",
    "        floors[f][\"combat_turns\"] = d.get(\"turns\", 0)\n",
    "\n",
    "\n",
    "def add_deck_state(run: dict, floors: list[dict]):\n",
    "    \"\"\"CORE FUNCTION: Build a per-floor running deck list\"\"\"\n",
    "    deck = deepcopy(get_starting_deck(run))\n",
    "    purges = run.get(\"items_purged\", [])\n",
    "    purchase_floors = run.get(\"item_purchase_floors\", [])\n",
    "    campfires = run.get(\"campfire_choices\", [])\n",
    "    card_choices = run.get(\"card_choices\", [])\n",
    "    event_choices = run.get(\"event_choices\", [])\n",
    "\n",
    "    for i, floor in enumerate(floors):\n",
    "        # Add Cards picked through the traditional method\n",
    "        for c in card_choices:\n",
    "            f = safe_get_floor(c)\n",
    "            if f is None:\n",
    "                return\n",
    "            if f == i and c.get(\"picked\") != \"SKIP\":\n",
    "                deck.append(c[\"picked\"])\n",
    "\n",
    "        # Add cards obtained through events\n",
    "        for ev in event_choices:\n",
    "            f = safe_get_floor(ev)\n",
    "            if f is None:\n",
    "                return\n",
    "            if f == i and ev.get(\"cards_obtained\"):\n",
    "                for card in ev[\"cards_obtained\"]:\n",
    "                    deck.append(card)\n",
    "\n",
    "        # Remove cards that were purged from the deck\n",
    "        for purge, pf in zip(purges, purchase_floors):\n",
    "            if pf == i and purge in deck:\n",
    "                deck.remove(purge)\n",
    "\n",
    "        # Upgrade Cards when SMITH'ed in a campfire\n",
    "        for camp in [\n",
    "            c for c in campfires if safe_get_floor(c) == i and c[\"key\"] == \"SMITH\"\n",
    "        ]:\n",
    "            target = camp.get(\"data\")\n",
    "            if target and target in deck:\n",
    "                deck.remove(target)\n",
    "                deck.append(f\"{target}+1\")\n",
    "\n",
    "        # Give the running state of the deck to this floor\n",
    "        floor[\"deck\"] = deepcopy(deck)\n",
    "        floor[\"deck_size\"] = len(deck)\n",
    "\n",
    "\n",
    "def add_relic_state(run: dict, floors: list[dict]):\n",
    "    relics = []\n",
    "    start_relics = run.get(\"relics\", [])\n",
    "    if start_relics:\n",
    "        relics.append(start_relics[0])\n",
    "\n",
    "    for r in run.get(\"relics_obtained\", []):\n",
    "        f = safe_get_floor(r)\n",
    "        if f is None:\n",
    "            return\n",
    "        if f == 0 and r.get(\"key\") not in relics:\n",
    "            relics.append(r[\"key\"])\n",
    "\n",
    "    event_choices = run.get(\"event_choices\", [])\n",
    "    relic_events = run.get(\"relics_obtained\", [])\n",
    "    boss_relics = run.get(\"boss_relics\", [])\n",
    "    boss_floors = [\n",
    "        i for i, f in enumerate(floors) if f.get(\"path_symbol\") in (\"B\", \"BOSS\")\n",
    "    ]\n",
    "    boss_relic_index = 0\n",
    "\n",
    "    for f in range(len(floors)):\n",
    "        # Track relics obtained from relic_events\n",
    "        for r in relic_events:\n",
    "            rf = safe_get_floor(r)\n",
    "            if rf is None:\n",
    "                return\n",
    "            if rf == f and r[\"key\"] not in relics:\n",
    "                relics.append(r[\"key\"])\n",
    "\n",
    "        # Track relics obtained from `relics_obtained` in events\n",
    "        for ev in event_choices:\n",
    "            ef = safe_get_floor(ev)\n",
    "            if ef is None:\n",
    "                return\n",
    "            if ef == f and ev.get(\"relics_obtained\"):\n",
    "                for rk in ev[\"relics_obtained\"]:\n",
    "                    if rk not in relics:\n",
    "                        relics.append(rk)\n",
    "\n",
    "        # Track boss relics\n",
    "        if f in boss_floors and boss_relic_index < len(boss_relics):\n",
    "            picked = boss_relics[boss_relic_index].get(\"picked\")\n",
    "            if picked and picked not in relics:\n",
    "                relics.append(picked)\n",
    "            boss_relic_index += 1\n",
    "\n",
    "        floors[f][\"relics\"] = relics.copy()\n",
    "        floors[f][\"num_relics\"] = len(relics)\n",
    "\n",
    "\n",
    "def get_starting_deck(run: dict) -> list[str]:\n",
    "    \"\"\"Infer the starting deck based on character and initial data.\"\"\"\n",
    "    char = run.get(\"character_chosen\", \"\")\n",
    "    if char == \"IRONCLAD\":\n",
    "        return [\"Strike_R\"] * 5 + [\"Defend_R\"] * 4 + [\"Bash\"]\n",
    "    elif char == \"THE_SILENT\":\n",
    "        return [\"Strike_G\"] * 5 + [\"Defend_G\"] * 5 + [\"Survivor\", \"Neutralize\"]\n",
    "    elif char == \"DEFECT\":\n",
    "        return [\"Strike_B\"] * 4 + [\"Defend_B\"] * 4 + [\"Zap\", \"Dualcast\"]\n",
    "    elif char == \"WATCHER\":\n",
    "        return [\"Strike_P\"] * 4 + [\"Defend_P\"] * 4 + [\"Eruption\", \"Vigilance\"]\n",
    "    raise KeyError(f\"Invalid Character Chose {char}\")\n",
    "\n",
    "\n",
    "# MAIN FUNCTION\n",
    "def load_all_runs(data: list[dict], increment: int) -> list[dict]:\n",
    "    \"\"\"\n",
    "    Process a list of Slay the Spire run JSONs with a progress bar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data : list[dict]\n",
    "        A list of runs loaded from the game logs.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    all_rows : list[dict]\n",
    "        A flattened list of floor-level records from all runs.\n",
    "    increment: int\n",
    "        Log the results every `increment` runs processed\n",
    "    \"\"\"\n",
    "    all_rows = []\n",
    "    total_runs = len(data)\n",
    "    console.print(f\"[bold cyan]Starting to process {total_runs} runs...[/bold cyan]\")\n",
    "\n",
    "    for i, run in enumerate(data):\n",
    "        try:\n",
    "            rows = process_run(run, i)\n",
    "            if rows:\n",
    "                all_rows.extend(rows)\n",
    "        except Exception as e:\n",
    "            console.print(f\"[red]Run {i} failed:[/red] {e}\")\n",
    "        finally:\n",
    "            if i % increment == 0:\n",
    "                console.print(f\"[deep_sky_blue4]Processed run {i}\")\n",
    "\n",
    "    console.print(\n",
    "        f\"\\n[bold green]✅ Finished processing {len(all_rows)} floor records \"\n",
    "        f\"from {total_runs} runs.[/bold green]\"\n",
    "    )\n",
    "    return all_rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418570af",
   "metadata": {},
   "source": [
    "Now that we've defined these helper functions, let's go ahead and process the complete dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fda6147c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">=====================================================================\n",
       "</pre>\n"
      ],
      "text/plain": [
       "=====================================================================\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Beginning JSON file load.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Beginning JSON file load.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #c0c0c0; text-decoration-color: #c0c0c0\">JSON data loaded</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[37mJSON data loaded\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">Starting to process </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123436</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> runs...</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36mStarting to process \u001b[0m\u001b[1;36m123436\u001b[0m\u001b[1;36m runs\u001b[0m\u001b[1;36m...\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">0</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m0\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">10000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m10000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">20000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m20000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">30000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m30000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">40000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m40000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">50000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m50000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">60000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m60000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">70000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m70000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">80000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m80000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">90000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m90000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">100000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m100000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">110000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m110000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #005faf; text-decoration-color: #005faf\">Processed run </span><span style=\"color: #005faf; text-decoration-color: #005faf; font-weight: bold\">120000</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[38;5;25mProcessed run \u001b[0m\u001b[1;38;5;25m120000\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">✅ Finished processing </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">3010112</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> floor records from </span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\">123436</span><span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> runs.</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;32m✅ Finished processing \u001b[0m\u001b[1;32m3010112\u001b[0m\u001b[1;32m floor records from \u001b[0m\u001b[1;32m123436\u001b[0m\u001b[1;32m runs.\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Data loaded to pandas dataframe</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mData loaded to pandas dataframe\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">Data written to ..\\data\\processed_sample.csv</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32mData written to ..\\data\\processed_sample.csv\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "repo_path = '..'\n",
    "# Cross-OS safe way of accessing data when ran locally\n",
    "data_path = os.path.join(repo_path, \"data\", \"sample.json\")\n",
    "output_path = os.path.join(repo_path, \"data\", \"processed_sample.csv\")\n",
    "# * NOT RESISTANT TO REPO STRUCTURE CHANGE\n",
    "console.print(\n",
    "    \"=====================================================================\"\n",
    ")\n",
    "console.print(\"[bold gray]Beginning JSON file load.\")\n",
    "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    data = json.load(f)\n",
    "console.print(\"[white]JSON data loaded\")\n",
    "all_rows = load_all_runs(data, increment=10_000)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "# Overwrite the current CSV\n",
    "console.print(\"[green]Data loaded to pandas dataframe\")\n",
    "df.to_csv(output_path, index=False, mode=\"w\")\n",
    "console.print(f\"[green]Data written to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sts-win-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
